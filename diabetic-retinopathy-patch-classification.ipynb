{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10447112,"sourceType":"datasetVersion","datasetId":6291062},{"sourceId":227081,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":193634,"modelId":215559}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ***importing Libraries***","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model, Sequential\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.layers import Flatten, Dense, Input, Conv2D, concatenate, BatchNormalization, MaxPooling2D, UpSampling2D, Concatenate, Dropout, Cropping2D, ZeroPadding2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom sklearn.metrics import jaccard_score\nimport matplotlib.pyplot as plt\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom tensorflow.keras.metrics import MeanIoU","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T03:48:24.883806Z","iopub.execute_input":"2025-01-12T03:48:24.884011Z","iopub.status.idle":"2025-01-12T03:48:24.888387Z","shell.execute_reply.started":"2025-01-12T03:48:24.883993Z","shell.execute_reply":"2025-01-12T03:48:24.887728Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ***1. DataLoading***","metadata":{}},{"cell_type":"code","source":"TRAIN_IMAGE_DIR = \"/kaggle/input/diabetic-retinopathy-dataset/Daataset_DR/DB0/Images\"\nTRAIN_MASK_DIR = \"/kaggle/input/diabetic-retinopathy-dataset/Daataset_DR/DB0/GroundTruth\"\nTEST_IMAGE_DIR = \"/kaggle/input/diabetic-retinopathy-dataset/Daataset_DR/DB1/Images\"\nTEST_MASK_DIR = \"/kaggle/input/diabetic-retinopathy-dataset/Daataset_DR/DB1/GroundTruth\"\nTRAIN_MASKS = \"/kaggle/working/CombinedMasksTask1\"\nTEST_MASKS = \"/kaggle/working/TestCombinedMasksTask1\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T03:48:24.889213Z","iopub.execute_input":"2025-01-12T03:48:24.889414Z","iopub.status.idle":"2025-01-12T03:48:24.905943Z","shell.execute_reply.started":"2025-01-12T03:48:24.889395Z","shell.execute_reply":"2025-01-12T03:48:24.905092Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ***1. Combining Masks of CWS and HE, both for training and testing***","metadata":{}},{"cell_type":"code","source":"def create_combined_mask(image_filename):\n    sample_mask_path = os.path.join(TRAIN_MASK_DIR, mask_subfolders[0], image_filename)\n    mask_shape = cv2.imread(sample_mask_path, cv2.IMREAD_GRAYSCALE).shape\n    combined_mask = np.zeros(mask_shape, dtype=np.uint8)\n\n    for subfolder in mask_subfolders:\n        mask_path = os.path.join(TRAIN_MASK_DIR, subfolder, image_filename)\n        if os.path.exists(mask_path):\n            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n            combined_mask = cv2.bitwise_or(combined_mask, mask)\n    return combined_mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T03:48:24.906741Z","iopub.execute_input":"2025-01-12T03:48:24.906996Z","iopub.status.idle":"2025-01-12T03:48:24.919548Z","shell.execute_reply.started":"2025-01-12T03:48:24.906970Z","shell.execute_reply":"2025-01-12T03:48:24.918882Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"OUTPUT_MASK_DIR = \"/kaggle/working/CombinedMasksTask1\"\nos.makedirs(OUTPUT_MASK_DIR, exist_ok=True)\nmask_subfolders = ['CWS', 'HE']\nimage_filenames = os.listdir(TRAIN_IMAGE_DIR)\n\nfor image_filename in tqdm(image_filenames):\n    combined_mask = create_combined_mask(image_filename)\n    output_path = os.path.join(OUTPUT_MASK_DIR, image_filename)\n    cv2.imwrite(output_path, combined_mask)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T03:48:24.920263Z","iopub.execute_input":"2025-01-12T03:48:24.920590Z","iopub.status.idle":"2025-01-12T03:48:27.536469Z","shell.execute_reply.started":"2025-01-12T03:48:24.920562Z","shell.execute_reply":"2025-01-12T03:48:27.535771Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"OUTPUT_MASK_DIR = \"/kaggle/working/TestCombinedMasksTask1\"\nos.makedirs(OUTPUT_MASK_DIR, exist_ok=True)\nmask_subfolders = ['CWS', 'HE']\nimage_filenames = os.listdir(TEST_IMAGE_DIR)\n\nfor image_filename in tqdm(image_filenames):\n    combined_mask = create_combined_mask(image_filename)\n    output_path = os.path.join(OUTPUT_MASK_DIR, image_filename)\n    cv2.imwrite(output_path, combined_mask)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T03:16:29.025126Z","iopub.execute_input":"2025-01-12T03:16:29.025428Z","iopub.status.idle":"2025-01-12T03:16:30.800684Z","shell.execute_reply.started":"2025-01-12T03:16:29.025404Z","shell.execute_reply":"2025-01-12T03:16:30.799989Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ***Checking if the masks are correctly combined***","metadata":{}},{"cell_type":"code","source":"def display_masks_comparison(train_image_dir, train_mask_dir, output_mask_dir, mask_classes, num_images=5):\n    image_filenames = os.listdir(train_image_dir)\n    plt.figure(figsize=(15, 10))\n    for i, filename in enumerate(image_filenames[15:20]):\n        # Load the original image\n        orig_image_path = os.path.join(train_image_dir, filename)\n        orig_image = cv2.imread(orig_image_path)\n        orig_image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB)\n        \n        # Initialize subplot for original image\n        plt.subplot(num_images, 4, i*4 + 1)\n        plt.imshow(orig_image)\n        plt.title('Original Image')\n        plt.axis('off')\n\n        # Load and display individual masks\n        for j, mask_class in enumerate(mask_classes):\n            mask_path = os.path.join(train_mask_dir, mask_class, filename)\n            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n            plt.subplot(num_images, 4, i*4 + 2 + j)\n            plt.imshow(mask, cmap='gray')\n            plt.title(f'Mask: {mask_class}')\n            plt.axis('off')\n\n        # Load and display the combined mask\n        combined_mask_path = os.path.join(output_mask_dir, filename)\n        combined_mask = cv2.imread(combined_mask_path, cv2.IMREAD_GRAYSCALE)\n        plt.subplot(num_images, 4, i*4 + 4)\n        plt.imshow(combined_mask, cmap='gray')\n        plt.title('Combined Mask')\n        plt.axis('off')\n        \n    plt.tight_layout()\n    plt.show()\n\ndisplay_masks_comparison(TRAIN_IMAGE_DIR, TRAIN_MASK_DIR, TRAIN_MASKS, mask_subfolders)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T02:47:53.747128Z","iopub.execute_input":"2025-01-12T02:47:53.747412Z","iopub.status.idle":"2025-01-12T02:47:57.320285Z","shell.execute_reply.started":"2025-01-12T02:47:53.747389Z","shell.execute_reply":"2025-01-12T02:47:57.319459Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ***2. Loading Images and Masks***","metadata":{}},{"cell_type":"code","source":"def load_data(image_dir, mask_dir):\n    image_filenames = sorted(os.listdir(image_dir))\n    images = []\n    masks = []\n    \n    for filename in tqdm(image_filenames, desc=\"Loading data\"):\n        # Load and resize image\n        image_path = os.path.join(image_dir, filename)\n        image = cv2.imread(image_path)\n        images.append(image)  # Normalize image to [0, 1]\n        \n        mask_path = os.path.join(mask_dir, filename)\n        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n        mask = (mask > 0).astype(np.uint8)  # Binarize mask (0 or 1)\n        masks.append(mask)\n    \n    return np.array(images), np.array(masks)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T02:47:57.495278Z","iopub.execute_input":"2025-01-12T02:47:57.495596Z","iopub.status.idle":"2025-01-12T02:47:57.500562Z","shell.execute_reply.started":"2025-01-12T02:47:57.495571Z","shell.execute_reply":"2025-01-12T02:47:57.499719Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images, masks = load_data(TRAIN_IMAGE_DIR, TRAIN_MASKS)\n\nX_train, X_val, y_train, y_val = train_test_split(images, masks, test_size=0.1, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T02:47:59.598661Z","iopub.execute_input":"2025-01-12T02:47:59.598972Z","iopub.status.idle":"2025-01-12T02:48:07.517922Z","shell.execute_reply.started":"2025-01-12T02:47:59.598948Z","shell.execute_reply":"2025-01-12T02:48:07.517238Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ***3. Dividing Images into 16X16 patches***","metadata":{}},{"cell_type":"code","source":"def data_patches(image_data):\n    # Define patch size\n    patch_size = 16\n\n    # Get the dimensions of the image\n    num_rows, num_cols, num_bands = image_data.shape\n\n    # Initialize an empty list to store patches\n    patches = []\n\n    # Loop over the image in patches of 16x16\n    for row in range(0, num_rows, patch_size):\n        for col in range(0, num_cols, patch_size):\n            # Extract the patch\n            patch = image_data[row:row+patch_size, col:col+patch_size]\n\n            # Check if the patch has the right shape (i.e., it's not on the edge)\n            if patch.shape[:2] == (patch_size, patch_size):\n                patches.append(patch)\n\n    # Convert list of patches to numpy array\n    patches_array = np.array(patches)\n    return patches_array","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T02:48:09.828422Z","iopub.execute_input":"2025-01-12T02:48:09.828748Z","iopub.status.idle":"2025-01-12T02:48:09.833655Z","shell.execute_reply.started":"2025-01-12T02:48:09.828688Z","shell.execute_reply":"2025-01-12T02:48:09.832796Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_patches = []\n\nfor a in X_train:\n    patches = data_patches(a)\n    train_patches.append(patches)\n\ntrain_patches = np.concatenate(train_patches, axis=0)\ntrain_patches.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T02:48:11.169405Z","iopub.execute_input":"2025-01-12T02:48:11.169761Z","iopub.status.idle":"2025-01-12T02:48:12.456273Z","shell.execute_reply.started":"2025-01-12T02:48:11.169729Z","shell.execute_reply":"2025-01-12T02:48:12.455581Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"validation_patches = []\nfor a in X_val:\n    patches = data_patches(a)\n    validation_patches.append(patches)\n\nvalidation_patches = np.concatenate(validation_patches, axis=0)\nvalidation_patches.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T02:48:15.498129Z","iopub.execute_input":"2025-01-12T02:48:15.498440Z","iopub.status.idle":"2025-01-12T02:48:15.671825Z","shell.execute_reply.started":"2025-01-12T02:48:15.498418Z","shell.execute_reply":"2025-01-12T02:48:15.671039Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ***4. Converting Masks into 16X16 patches and assigning each patch a label accordingly***\nEither 1 or 0, 1 means the patch contains disease, 0 means it doesn't","metadata":{}},{"cell_type":"markdown","source":"#### ***Patch Size 8X8***","metadata":{}},{"cell_type":"code","source":"def label_patches(image):\n    patch_size = 8\n    labeled_patches = []  # List to hold the label of each patch\n\n    # Loop over the image in patches of 8x8\n    for row in range(0, image.shape[0], patch_size):\n        for col in range(0, image.shape[1], patch_size):\n            # Extract the patch\n            patch = image[row:row + patch_size, col:col + patch_size]\n\n            # Check if the patch has the correct shape (i.e., it's not on the edge)\n            if patch.shape[:2] == (patch_size, patch_size):\n                # Flatten the patch and calculate the most frequent value (label)\n                flattened_patch = patch.flatten()\n                counts = np.bincount(flattened_patch)\n                most_frequent = np.argmax(counts)\n                labeled_patches.append(most_frequent)  # Append label of the patch\n\n    return np.array(labeled_patches)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T02:48:19.316386Z","iopub.execute_input":"2025-01-12T02:48:19.316679Z","iopub.status.idle":"2025-01-12T02:48:19.321755Z","shell.execute_reply.started":"2025-01-12T02:48:19.316656Z","shell.execute_reply":"2025-01-12T02:48:19.320893Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### ***Patch Size 16X16***","metadata":{}},{"cell_type":"code","source":"def label_patches2(image):\n    patch_size = 16\n    labeled_patches = []  # List to hold the label of each patch\n\n    # Loop over the image in patches of 8x8\n    for row in range(0, image.shape[0], patch_size):\n        for col in range(0, image.shape[1], patch_size):\n            # Extract the patch\n            patch = image[row:row + patch_size, col:col + patch_size]\n\n            # Check if the patch has the correct shape (i.e., it's not on the edge)\n            if patch.shape[:2] == (patch_size, patch_size):\n                # Check if there is at least one pixel with the value 1\n                if 1 in patch:\n                    labeled_patches.append(1)\n                else:\n                    labeled_patches.append(0)\n\n    return np.array(labeled_patches)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T02:48:21.584391Z","iopub.execute_input":"2025-01-12T02:48:21.584716Z","iopub.status.idle":"2025-01-12T02:48:21.589620Z","shell.execute_reply.started":"2025-01-12T02:48:21.584672Z","shell.execute_reply":"2025-01-12T02:48:21.588687Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_labels = []\n\nfor a in y_train:\n    labels = label_patches2(a)\n    train_labels.extend(labels)\n\ntrain_labels = np.array(train_labels)\ntrain_labels.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T02:48:25.209046Z","iopub.execute_input":"2025-01-12T02:48:25.209333Z","iopub.status.idle":"2025-01-12T02:48:29.583022Z","shell.execute_reply.started":"2025-01-12T02:48:25.209310Z","shell.execute_reply":"2025-01-12T02:48:29.582245Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"validation_labels = []\n\nfor a in y_val:\n    labels = label_patches2(a)\n    validation_labels.extend(labels)\n\nvalidation_labels = np.array(validation_labels)\nvalidation_labels.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T02:48:29.583905Z","iopub.execute_input":"2025-01-12T02:48:29.584110Z","iopub.status.idle":"2025-01-12T02:48:30.060130Z","shell.execute_reply.started":"2025-01-12T02:48:29.584093Z","shell.execute_reply":"2025-01-12T02:48:30.059338Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ***5. Model for doing patch classification***","metadata":{}},{"cell_type":"code","source":"def build_model():\n    model = Sequential()\n    model.add(Conv2D(128, (3, 3), activation='relu', padding='same', input_shape=(16, 16, 3)))\n    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n    model.add(Conv2D(1024, (3, 3), activation='relu', padding='same'))\n    model.add(Flatten())\n    model.add(Dense(256, activation='relu'))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dense(2, activation='sigmoid'))\n\n    # Compile the model\n    model.compile(optimizer=Adam(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n    # Model summary to check structure\n    return model\nmodel = build_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T02:48:33.918494Z","iopub.execute_input":"2025-01-12T02:48:33.918839Z","iopub.status.idle":"2025-01-12T02:48:34.650515Z","shell.execute_reply.started":"2025-01-12T02:48:33.918810Z","shell.execute_reply":"2025-01-12T02:48:34.649882Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T02:48:37.525159Z","iopub.execute_input":"2025-01-12T02:48:37.525454Z","iopub.status.idle":"2025-01-12T02:48:37.547611Z","shell.execute_reply.started":"2025-01-12T02:48:37.525433Z","shell.execute_reply":"2025-01-12T02:48:37.546613Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\n\n# Setup the ModelCheckpoint callback to save the best model based on validation accuracy\ncheckpoint = ModelCheckpoint(\n    'best_model.keras',  # Path where the model is saved\n    monitor='val_accuracy',  # Monitor validation accuracy\n    save_best_only=True,  # Only save the model if 'val_accuracy' has improved\n    mode='max',  # 'max' because we want to maximize validation accuracy\n    verbose=1  # Optional: provides detailed logging about the saved models\n)\n\n# Fit the model using the previously defined training and validation data\nhistory2 = model.fit(\n    train_patches, \n    train_labels, \n    validation_data=(validation_patches, validation_labels),\n    epochs=10,\n    batch_size=2048,\n    callbacks=[checkpoint]  # Include the checkpoint in the callbacks\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T02:48:43.619314Z","iopub.execute_input":"2025-01-12T02:48:43.619636Z","iopub.status.idle":"2025-01-12T03:07:12.456952Z","shell.execute_reply.started":"2025-01-12T02:48:43.619608Z","shell.execute_reply":"2025-01-12T03:07:12.456219Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ***6. Loading Data for testing***","metadata":{}},{"cell_type":"code","source":"IMAGE_DIR = \"/kaggle/input/diabetic-retinopathy-dataset/Daataset_DR/DB1/Images\"\nMASK_DIR = \"/kaggle/working/TestCombinedMasksTask1\"\ndef load_data(image_dir, mask_dir):\n    image_filenames = sorted(os.listdir(image_dir))\n    images = []\n    masks = []\n    \n    for filename in tqdm(image_filenames, desc=\"Loading data\"):\n        # Load and resize image\n        image_path = os.path.join(image_dir, filename)\n        image = cv2.imread(image_path)\n        images.append(image)\n        \n        mask_path = os.path.join(mask_dir, filename)\n        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n        mask = (mask > 0).astype(np.uint8) \n        masks.append(mask)\n    \n    return np.array(images), np.array(masks)\n\nX_test, y_test = load_data(IMAGE_DIR, MASK_DIR)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T03:16:37.818620Z","iopub.execute_input":"2025-01-12T03:16:37.818981Z","iopub.status.idle":"2025-01-12T03:16:42.901427Z","shell.execute_reply.started":"2025-01-12T03:16:37.818955Z","shell.execute_reply":"2025-01-12T03:16:42.900491Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_patches = []\n\nfor a in X_test:\n    patches = data_patches(a)\n    test_patches.append(patches)\n\ntest_patches = np.concatenate(test_patches, axis=0)\ntest_patches.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T03:16:49.166471Z","iopub.execute_input":"2025-01-12T03:16:49.166776Z","iopub.status.idle":"2025-01-12T03:16:50.258355Z","shell.execute_reply.started":"2025-01-12T03:16:49.166751Z","shell.execute_reply":"2025-01-12T03:16:50.257451Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_labels = []\n\nfor a in y_test:\n    labels = label_patches2(a)\n    test_labels.extend(labels)\n\ntest_labels = np.array(test_labels)\ntest_labels.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T03:16:54.128042Z","iopub.execute_input":"2025-01-12T03:16:54.128318Z","iopub.status.idle":"2025-01-12T03:16:57.413658Z","shell.execute_reply.started":"2025-01-12T03:16:54.128295Z","shell.execute_reply":"2025-01-12T03:16:57.412813Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ***7. Taking predictions***\n### ***Here the predictions are labels of the patches, we need to make picture from it***","metadata":{}},{"cell_type":"code","source":"model.evaluate(test_patches,test_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T03:17:01.740949Z","iopub.execute_input":"2025-01-12T03:17:01.741274Z","iopub.status.idle":"2025-01-12T03:18:11.888968Z","shell.execute_reply.started":"2025-01-12T03:17:01.741243Z","shell.execute_reply":"2025-01-12T03:18:11.888087Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions = model.predict(test_patches)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T03:18:44.238226Z","iopub.execute_input":"2025-01-12T03:18:44.238631Z","iopub.status.idle":"2025-01-12T03:19:44.953015Z","shell.execute_reply.started":"2025-01-12T03:18:44.238590Z","shell.execute_reply":"2025-01-12T03:19:44.952275Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict = np.argmax(predictions, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T03:19:54.376940Z","iopub.execute_input":"2025-01-12T03:19:54.377267Z","iopub.status.idle":"2025-01-12T03:19:54.386614Z","shell.execute_reply.started":"2025-01-12T03:19:54.377238Z","shell.execute_reply":"2025-01-12T03:19:54.385800Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ***8. Reconstructing patches from predicted labels***","metadata":{}},{"cell_type":"code","source":"pred = []\nfor x in predict:\n  pred.append(np.full((16, 16), x))\npred = np.array(pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T03:20:00.117561Z","iopub.execute_input":"2025-01-12T03:20:00.117938Z","iopub.status.idle":"2025-01-12T03:20:03.006011Z","shell.execute_reply.started":"2025-01-12T03:20:00.117908Z","shell.execute_reply":"2025-01-12T03:20:03.005236Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred2 = pred.reshape(89, 6696, 16,16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T03:20:09.278676Z","iopub.execute_input":"2025-01-12T03:20:09.279040Z","iopub.status.idle":"2025-01-12T03:20:09.282719Z","shell.execute_reply.started":"2025-01-12T03:20:09.279011Z","shell.execute_reply":"2025-01-12T03:20:09.281885Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ***Reconstructing Masks from patches***","metadata":{}},{"cell_type":"code","source":"predicted_masks = []\nfor a in pred2:\n    patches_per_row = 93\n    patches_per_col = len(a) // patches_per_row\n    image = np.concatenate([np.concatenate(a[i:i+patches_per_row], axis=1) for i in range(0, len(a), patches_per_row)], axis=0)\n    predicted_masks.append(image)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T03:20:14.245477Z","iopub.execute_input":"2025-01-12T03:20:14.245806Z","iopub.status.idle":"2025-01-12T03:20:15.308374Z","shell.execute_reply.started":"2025-01-12T03:20:14.245780Z","shell.execute_reply":"2025-01-12T03:20:15.307455Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(predicted_masks)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T03:20:30.113483Z","iopub.execute_input":"2025-01-12T03:20:30.113850Z","iopub.status.idle":"2025-01-12T03:20:30.118960Z","shell.execute_reply.started":"2025-01-12T03:20:30.113818Z","shell.execute_reply":"2025-01-12T03:20:30.117973Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ***9. Plotting all the predicted masks***","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Assuming 'predicted_masks' is your list or array of images\nnum_images = 89\nrows = 18\ncols = 5\n\nfig, axes = plt.subplots(rows, cols, figsize=(15, 54))  # Adjust figsize to your screen/display size\naxes = axes.flatten()  # Flatten the 2D array of axes to simplify the looping\n\n# Loop over all of the positions in the grid\nfor i in range(rows * cols):\n    if i < num_images:\n        # Display image\n        axes[i].imshow(predicted_masks[i], cmap='gray')  # Assuming masks are grayscale\n        axes[i].axis('off')  # Turn off axis numbering and ticks\n    else:\n        axes[i].axis('off')  # Make sure empty plots also have no axes\n\nplt.tight_layout()  # Optional, improves spacing between plots\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T03:20:33.337261Z","iopub.execute_input":"2025-01-12T03:20:33.337582Z","iopub.status.idle":"2025-01-12T03:20:44.524650Z","shell.execute_reply.started":"2025-01-12T03:20:33.337552Z","shell.execute_reply":"2025-01-12T03:20:44.523754Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ***10. Comparing Test Ground truth and predicted masks***","metadata":{}},{"cell_type":"code","source":"import matplotlib.image as mpimg\n\ntest_image_dir = \"/kaggle/input/diabetic-retinopathy-dataset/Daataset_DR/DB1/Images\"\nground_truth_dir = \"/kaggle/working/TestCombinedMasksTask1\"\nimage_files = sorted(os.listdir(test_image_dir))\nground_truth_files = sorted(os.listdir(ground_truth_dir))\n\nassert len(image_files) == len(ground_truth_files) == 89, \"Mismatch in number of files\"\n\nnum_images = len(image_files)\nfig, axes = plt.subplots(num_images, 3, figsize=(15, 5 * num_images))\n\nfor i, image_file in enumerate(image_files):\n    # Read the image and the ground truth mask\n    img_path = os.path.join(test_image_dir, image_file)\n    gt_path = os.path.join(ground_truth_dir, ground_truth_files[i])\n\n    image = mpimg.imread(img_path)\n    ground_truth = mpimg.imread(gt_path)\n    predicted_mask = predicted_masks[i]\n\n    # Plotting\n    axes[i, 0].imshow(image)\n    axes[i, 0].set_title('Original Image')\n    axes[i, 0].axis('off')\n\n    axes[i, 1].imshow(ground_truth)\n    axes[i, 1].set_title('Ground Truth Mask')\n    axes[i, 1].axis('off')\n\n    axes[i, 2].imshow(predicted_mask)\n    axes[i, 2].set_title('Predicted Mask')\n    axes[i, 2].axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T03:23:49.900409Z","iopub.execute_input":"2025-01-12T03:23:49.900691Z","iopub.status.idle":"2025-01-12T03:24:56.239578Z","shell.execute_reply.started":"2025-01-12T03:23:49.900670Z","shell.execute_reply":"2025-01-12T03:24:56.238628Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### ***adding extra pading to retain the orignal size --- discorded during pachification***","metadata":{}},{"cell_type":"code","source":"padded_masks = np.array([np.pad(mask, pad_width=((0, 0), (0, 12)), mode='constant', constant_values=0) for mask in predicted_masks])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T03:28:33.834431Z","iopub.execute_input":"2025-01-12T03:28:33.834807Z","iopub.status.idle":"2025-01-12T03:28:34.743459Z","shell.execute_reply.started":"2025-01-12T03:28:33.834777Z","shell.execute_reply":"2025-01-12T03:28:34.742493Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ***Finding IOU Score***","metadata":{}},{"cell_type":"code","source":"def iou_score(y_true, y_pred):\n    intersection = np.logical_and(y_true, y_pred).sum()\n    union = np.logical_or(y_true, y_pred).sum()\n    if union == 0:\n        return 1.0  # To handle cases with no ground truth or predicted objects\n    else:\n        return intersection / union","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T03:28:38.533077Z","iopub.execute_input":"2025-01-12T03:28:38.533373Z","iopub.status.idle":"2025-01-12T03:28:38.537502Z","shell.execute_reply.started":"2025-01-12T03:28:38.533352Z","shell.execute_reply":"2025-01-12T03:28:38.536757Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Ensure both padded_masks and y_test are NumPy arrays and have the same dimensions\nassert padded_masks.shape == y_test.shape, \"The dimensions of padded_masks and y_test must match.\"\n\n# Calculate IoU scores for each corresponding pair of masks\niou_scores = [iou_score(true, pred) for true, pred in zip(y_test, padded_masks)]\n\n# Calculate mean IoU across all mask pairs\nmean_iou = np.mean(iou_scores)\nprint(\"Mean IoU:\", mean_iou)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T03:28:40.145351Z","iopub.execute_input":"2025-01-12T03:28:40.145658Z","iopub.status.idle":"2025-01-12T03:28:40.629109Z","shell.execute_reply.started":"2025-01-12T03:28:40.145634Z","shell.execute_reply":"2025-01-12T03:28:40.628271Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport os\nfrom tensorflow.keras.models import load_model\n\ndef data_patches(image_data, patch_size=16):\n    \"\"\"\n    Extracts non-overlapping patches of size `patch_size x patch_size`.\n    Ignores edges that don't fit exactly.\n    \"\"\"\n    num_rows, num_cols, num_bands = image_data.shape\n    patches = []\n    \n    for row in range(0, num_rows, patch_size):\n        for col in range(0, num_cols, patch_size):\n            patch = image_data[row:row+patch_size, col:col+patch_size]\n            # Keep only full patches\n            if patch.shape[:2] == (patch_size, patch_size):\n                patches.append(patch)\n    \n    return np.array(patches)\n\ndef reassemble_patches(patches, original_shape, patch_size=16):\n    \"\"\"\n    Reassembles patches of size `patch_size x patch_size` into a single 2D mask.\n    Expects `original_shape` = (height, width).\n    \"\"\"\n    h, w = original_shape\n    patches_per_row = w // patch_size\n    patches_per_col = h // patch_size\n    \n    # Reshape patches into (patches_per_col * patches_per_row, patch_size, patch_size)\n    # so we can iterate in row-major order\n    patches = patches.reshape(patches_per_col * patches_per_row, patch_size, patch_size)\n    \n    # Build each row by concatenating patches horizontally\n    rows = []\n    idx = 0\n    for _ in range(patches_per_col):\n        row_patches = patches[idx:idx+patches_per_row]\n        row_image = np.concatenate(row_patches, axis=1)\n        rows.append(row_image)\n        idx += patches_per_row\n    \n    # Stack rows vertically\n    full_mask = np.concatenate(rows, axis=0)\n    return full_mask\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T06:54:10.573164Z","iopub.execute_input":"2025-01-12T06:54:10.573516Z","iopub.status.idle":"2025-01-12T06:54:18.354191Z","shell.execute_reply.started":"2025-01-12T06:54:10.573490Z","shell.execute_reply":"2025-01-12T06:54:18.353444Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_mask_for_image(image_path, model, patch_size=16):\n    \"\"\"\n    1. Reads and preprocesses the image.\n    2. Extracts patches, does inference, and reassembles them into a binary mask.\n    3. Returns the predicted mask (same height & width as input, 1 channel).\n    \"\"\"\n    # --- Load image ---\n    image = cv2.imread(image_path)\n    original_h, original_w, _ = image.shape\n    \n    # --- Extract patches ---\n    patches = data_patches(image, patch_size=patch_size)\n    \n    # Model expects the shape (num_patches, patch_size, patch_size, 3)\n    # Convert to float / normalize if needed (depends on your training pipeline)\n    patches = patches.astype(np.float32) / 255.0  # Example normalization\n    \n    # --- Predict on patches ---\n    predictions = model.predict(patches)  # Shape: (num_patches, 2)\n    \n    # Argmax over the class dimension => 0 or 1 per patch\n    patch_labels = np.argmax(predictions, axis=1)  # Shape: (num_patches,)\n    \n    # --- Convert each patch label to a (patch_size x patch_size) block ---\n    # If label=1, create a block of ones. Otherwise, zeros.\n    labeled_patches = []\n    for lbl in patch_labels:\n        block = np.full((patch_size, patch_size), lbl, dtype=np.uint8)\n        labeled_patches.append(block)\n    labeled_patches = np.array(labeled_patches)\n    \n    # --- Reassemble labeled patches into a single 2D mask ---\n    full_mask = reassemble_patches(labeled_patches, (original_h, original_w), patch_size=patch_size)\n    \n    return full_mask\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T06:54:25.578492Z","iopub.execute_input":"2025-01-12T06:54:25.579084Z","iopub.status.idle":"2025-01-12T06:54:25.584888Z","shell.execute_reply.started":"2025-01-12T06:54:25.579052Z","shell.execute_reply":"2025-01-12T06:54:25.583874Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load your trained model (either the best_model.keras or the final model)\nmodel = load_model(\"/kaggle/input/patch1/keras/default/1/best_model.keras\")\n\n# Example image path\ntest_image_path = \"/kaggle/input/diabetic-retinopathy-dataset/Daataset_DR/DB1/Images/image003.png\"\n\n# Generate the predicted mask\npredicted_mask = predict_mask_for_image(test_image_path, model, patch_size=16)\n\n# Save or display the result\ncv2.imwrite(\"predicted_mask.png\", predicted_mask * 255)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T06:55:14.888218Z","iopub.execute_input":"2025-01-12T06:55:14.888541Z","iopub.status.idle":"2025-01-12T06:55:25.617766Z","shell.execute_reply.started":"2025-01-12T06:55:14.888519Z","shell.execute_reply":"2025-01-12T06:55:25.616840Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}