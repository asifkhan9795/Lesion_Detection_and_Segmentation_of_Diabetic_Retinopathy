{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10447112,"sourceType":"datasetVersion","datasetId":6291062}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ***Loading Libaries***","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model, Sequential\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.layers import Flatten, Dense, Input, Conv2D, concatenate, BatchNormalization, MaxPooling2D, UpSampling2D, Concatenate, Dropout, Cropping2D, ZeroPadding2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom sklearn.metrics import jaccard_score\nimport matplotlib.pyplot as plt\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom tensorflow.keras.metrics import MeanIoU\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom torchvision.transforms import ToTensor\nfrom transformers import ViTModel, ViTConfig\nimport torchvision.models as models","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ***DataLoading***","metadata":{}},{"cell_type":"code","source":"TRAIN_IMAGE_DIR = \"/kaggle/input/diabetic-retinopathy-dataset/Daataset_DR/DB0/Images\"\nTRAIN_MASK_DIR = \"/kaggle/input/diabetic-retinopathy-dataset/Daataset_DR/DB0/GroundTruth\"\nTEST_IMAGE_DIR = \"/kaggle/input/diabetic-retinopathy-dataset/Daataset_DR/DB1/Images\"\nTEST_MASK_DIR = \"/kaggle/input/diabetic-retinopathy-dataset/Daataset_DR/DB1/GroundTruth\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ***1. Combining Masks***","metadata":{}},{"cell_type":"code","source":"def create_combined_mask(image_filename):\n    sample_mask_path = os.path.join(TRAIN_MASK_DIR, mask_subfolders[0], image_filename)\n    mask_shape = cv2.imread(sample_mask_path, cv2.IMREAD_GRAYSCALE).shape\n    combined_mask = np.zeros(mask_shape, dtype=np.uint8)\n\n    for subfolder in mask_subfolders:\n        mask_path = os.path.join(TRAIN_MASK_DIR, subfolder, image_filename)\n        if os.path.exists(mask_path):\n            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n            combined_mask = cv2.bitwise_or(combined_mask, mask)\n\n    return combined_mask","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ***Bright Lesion***","metadata":{}},{"cell_type":"code","source":"OUTPUT_MASK_DIR = \"/kaggle/working/CombinedMasksTask1\"\nos.makedirs(OUTPUT_MASK_DIR, exist_ok=True)\nmask_subfolders = ['CWS', 'HE']\nimage_filenames = os.listdir(TRAIN_IMAGE_DIR)\n\nfor image_filename in tqdm(image_filenames):\n    combined_mask = create_combined_mask(image_filename)\n    output_path = os.path.join(OUTPUT_MASK_DIR, image_filename)\n    cv2.imwrite(output_path, combined_mask)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"OUTPUT_MASK_DIR = \"/kaggle/working/TestCombinedMasksTask1\"\nos.makedirs(OUTPUT_MASK_DIR, exist_ok=True)\nmask_subfolders = ['CWS', 'HE']\nimage_filenames = os.listdir(TEST_IMAGE_DIR)\n\nfor image_filename in tqdm(image_filenames):\n    combined_mask = create_combined_mask(image_filename)\n    output_path = os.path.join(OUTPUT_MASK_DIR, image_filename)\n    cv2.imwrite(output_path, combined_mask)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ***Darker Lesion***","metadata":{}},{"cell_type":"code","source":"OUTPUT_MASK_DIR = \"/kaggle/working/CombinedMasksTask2\"\nos.makedirs(OUTPUT_MASK_DIR, exist_ok=True)\nmask_subfolders = ['H', 'MA']\nimage_filenames = sorted(os.listdir(TRAIN_IMAGE_DIR))\n\nfor image_filename in tqdm(image_filenames):\n    combined_mask = create_combined_mask(image_filename)\n    output_path = os.path.join(OUTPUT_MASK_DIR, image_filename)\n    cv2.imwrite(output_path, combined_mask)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"OUTPUT_MASK_DIR = \"/kaggle/working/TestCombinedMasksTask2\"\nos.makedirs(OUTPUT_MASK_DIR, exist_ok=True)\nmask_subfolders = ['H', 'MA']\nimage_filenames = os.listdir(TEST_IMAGE_DIR)\n\nfor image_filename in tqdm(image_filenames):\n    combined_mask = create_combined_mask(image_filename)\n    output_path = os.path.join(OUTPUT_MASK_DIR, image_filename)\n    cv2.imwrite(output_path, combined_mask)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ***2. Loading Images and Masks***","metadata":{}},{"cell_type":"code","source":"IMAGE_DIR = \"/kaggle/input/diabetic-retinopathy-dataset/Daataset_DR/DB0/Images\"\nMASK_DIR = \"/kaggle/working/CombinedMasksTask1\"\n\nIMG_HEIGHT = 1152\nIMG_WIDTH = 1500\nBATCH_SIZE = 1\nEPOCHS = 50\n\ndef load_data(image_dir, mask_dir):\n    image_filenames = sorted(os.listdir(image_dir))\n    images = []\n    masks = []\n    \n    for filename in tqdm(image_filenames, desc=\"Loading data\"):\n        # Load and resize image\n        image_path = os.path.join(image_dir, filename)\n        image = cv2.imread(image_path)\n        #image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n        images.append(image)  # Normalize image to [0, 1]\n        \n        # Load and resize mask\n        mask_path = os.path.join(mask_dir, filename)\n        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n        #mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT))\n        mask = (mask > 0).astype(np.uint8)  # Binarize mask (0 or 1)\n        masks.append(mask)\n    \n    return np.array(images), np.array(masks).reshape(-1, IMG_HEIGHT, IMG_WIDTH, 1)\n\nimages, masks = load_data(IMAGE_DIR, MASK_DIR)\n\n#X_train, X_val, y_train, y_val = train_test_split(images, masks, test_size=0.1, random_state=42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"IMAGE_DIR = \"/kaggle/input/diabetic-retinopathy-dataset/Daataset_DR/DB0/Images\"\nMASK_DIR = \"/kaggle/working/CombinedMasksTask2\"\n\nIMG_HEIGHT = 1152\nIMG_WIDTH = 1500\nBATCH_SIZE = 1\nEPOCHS = 50\n\ndef load_data(image_dir, mask_dir):\n    image_filenames = sorted(os.listdir(image_dir))\n    images = []\n    masks = []\n    \n    for filename in tqdm(image_filenames, desc=\"Loading data\"):\n        # Load and resize image\n        image_path = os.path.join(image_dir, filename)\n        image = cv2.imread(image_path)\n        #image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n        images.append(image)  # Normalize image to [0, 1]\n        \n        # Load and resize mask\n        mask_path = os.path.join(mask_dir, filename)\n        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n        #mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT))\n        mask = (mask > 0).astype(np.uint8)  # Binarize mask (0 or 1)\n        masks.append(mask)\n    \n    return np.array(images), np.array(masks).reshape(-1, IMG_HEIGHT, IMG_WIDTH, 1)\n\nimages, masks = load_data(IMAGE_DIR, MASK_DIR)\n\n#X_train, X_val, y_train, y_val = train_test_split(images, masks, test_size=0.1, random_state=42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ***SeTFormer MOdel***","metadata":{}},{"cell_type":"markdown","source":"## ***Data preprocessing***","metadata":{}},{"cell_type":"code","source":"def preprocess_image(image,mask= None):\n    ih, iw = 1024, 1024\n    image = cv2.resize(image, (ih, iw))\n    if mask == None :\n        image = image.reshape(-1, ih, iw, 3)\n    #print(image.shape)\n        image = torch.tensor(image, dtype=torch.float32).permute(0, 3, 2, 1)\n    else:\n        image = image.reshape(-1, ih, iw, 1)\n        image = torch.tensor(image, dtype=torch.float32).permute(0, 3, 2, 1)\n    #image = normalize(image)  # Normalize for ResNet\n    return image\nimages2 = [preprocess_image(image) for image in images]\nmasks2 = [preprocess_image(image, mask = 1) for image in masks]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images2[0].shape, masks2[0].shape, len(images2), len(masks2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ***Model***","metadata":{}},{"cell_type":"code","source":"target_size = (1024, 1024)\n\nclass SetFormer(nn.Module):\n    def __init__(self, num_classes=1):\n        super(SetFormer, self).__init__()\n        resnet = models.resnet101(pretrained=True)\n        self.encoder = nn.Sequential(*list(resnet.children())[:-2])\n\n        # Additional decoder layers with skip connections\n        self.segmentation_head = nn.Sequential(\n            nn.Conv2d(2048, 256, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n            nn.Conv2d(128, num_classes, kernel_size=1),\n            nn.Upsample(scale_factor=8, mode='bilinear', align_corners=True)\n        )\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.segmentation_head(x)\n        return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torchsummary\nfrom torchsummary import summary","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = SetFormer(num_classes=1).to(device)\n\n#Print model summary\nsummary(model, input_size=(3, 1024, 1024))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Dice Loss Function\ndef dice_loss(pred, target):\n    smooth = 1e-6\n    pred = torch.sigmoid(pred)\n    intersection = (pred * target).sum()\n    return 1 - (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)\n\nbce_loss = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epochs = 100\nfor epoch in range(epochs):\n    model.train()\n    epoch_loss = 0\n    for imgs, masks in zip(images2, masks2):\n        imgs, masks = imgs.to(device), masks.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(imgs)\n        \n        loss = bce_loss(outputs, masks)# + dice_loss(outputs, masks)\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n\n    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / len(images)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(type(model))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\n# Save the model's state dictionary\ntorch.save(model.state_dict(), '/kaggle/working/setformer_model.pth')\n\nprint(\"Model saved as 'setformer_model.pth'\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ***Grad_cam***","metadata":{}},{"cell_type":"code","source":"!pip install grad-cam","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ***Evaluation***","metadata":{}},{"cell_type":"code","source":"def predict(model, image, device, threshold=0.5):\n    model.eval()  # Set model to evaluation mode\n    input_tensor = preprocess_image(image).to(device)\n    with torch.no_grad():\n        output = model(input_tensor)\n    probabilities = torch.sigmoid(output)\n    binary_mask = (probabilities > threshold).int()\n    binary_mask = binary_mask.squeeze().cpu().numpy()\n    return binary_mask","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Directory path containing images\nimage_dir = \"/kaggle/input/diabetic-retinopathy-dataset/Daataset_DR/DB1/Images\"\n\n# Get the list of all images and sort them to ensure order\nimage_paths = sorted([os.path.join(image_dir, fname) for fname in os.listdir(image_dir) if fname.endswith('.png')])\n\n# Select the first 25 images\nselected_images = image_paths[:25]\n\n# Create a 5x5 grid plot\nfig, axes = plt.subplots(5, 5, figsize=(15, 15))\n\nfor i, ax in enumerate(axes.flat):\n    test_image_path = selected_images[i]\n    test_image = cv2.imread(test_image_path)\n    predicted_mask = predict(model, test_image, device)  # Assuming predict function is already defined\n    ax.imshow(predicted_mask)\n    ax.axis('off')  # Hide the axis for better visualization\n    ax.set_title(f\"Image {i+1}\")  # Optional: Set a title for each subplot\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_dir = \"/kaggle/working/CombinedMasksTask2\"\n\nimage_paths = sorted([os.path.join(image_dir, fname) for fname in os.listdir(image_dir) if fname.endswith('.png')])\n\n# Select the first 25 images\nselected_images = image_paths[:25]\n\n# Create a 5x5 grid plot\nfig, axes = plt.subplots(5, 5, figsize=(15, 15))\n\nfor i, ax in enumerate(axes.flat):\n    test_image_path = selected_images[i]\n    test_image = cv2.imread(test_image_path)\n    ax.imshow(test_image)\n    ax.axis('off')  # Hide the axis for better visualization\n    ax.set_title(f\"Image {i+1}\")  # Optional: Set a title for each subplot\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport cv2\nimport numpy as np\n\ndef visualize_predictions(images, predicted_masks):\n    \"\"\"\n    Visualizes a batch of original images and their predicted segmentation masks side by side.\n    - images: List of original input images (in RGB).\n    - predicted_masks: List of predicted binary segmentation masks.\n    \"\"\"\n    n = len(images)\n    plt.figure(figsize=(15, 6))\n    for i in range(n):\n        # Original image\n        plt.subplot(2, n, i + 1)\n        plt.imshow(cv2.cvtColor(images[i], cv2.COLOR_BGR2RGB))  # Convert BGR to RGB\n        plt.title(f\"Image {i+1}\")\n        plt.axis(\"off\")\n\n        # Predicted mask\n        plt.subplot(2, n, i + 1 + n)\n        plt.imshow(predicted_masks[i], cmap='gray')\n        plt.title(f\"Predicted Mask {i+1}\")\n        plt.axis(\"off\")\n\n    plt.tight_layout()\n    plt.show()\n\n# Load 10 test images\ntest_image_paths = [\n    \"/kaggle/input/diabetic-retinopathy-dataset/Daataset_DR/DB1/Images/image009.png\",\n    \"/kaggle/input/diabetic-retinopathy-dataset/Daataset_DR/DB1/Images/image007.png\",\n    # Add paths for 8 more images...\n]\ntest_images = [cv2.imread(path) for path in test_image_paths]\n\n# Predict masks for all 10 images\npredicted_masks = [predict(model, img, device) for img in test_images]\n\n# Visualize predictions\nvisualize_predictions(test_images, predicted_masks)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.unique(mask)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Ensure the mask is converted to integer type before using np.bincount\ntrue_mask = mask.astype(np.int32)\n\n# Flatten the mask and count the occurrences of each unique value\npixel_counts = np.bincount(true_mask.flatten())\n\n# Print the pixel counts for each class (excluding background if it's class 0)\nfor class_id, count in enumerate(pixel_counts):\n    print(f\"Class {class_id}: {count} pixels\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}