{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10447112,"sourceType":"datasetVersion","datasetId":6291062}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model, Sequential\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.layers import Flatten, Dense, Input, Conv2D, concatenate, BatchNormalization, MaxPooling2D, UpSampling2D, Concatenate, Dropout, Cropping2D, ZeroPadding2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom sklearn.metrics import jaccard_score\nimport matplotlib.pyplot as plt\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom tensorflow.keras.metrics import MeanIoU\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision.transforms import ToTensor\nfrom transformers import ViTModel, ViTConfig\nimport torchvision.models as models","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T10:01:08.647752Z","iopub.execute_input":"2025-01-14T10:01:08.648054Z","iopub.status.idle":"2025-01-14T10:01:30.054145Z","shell.execute_reply.started":"2025-01-14T10:01:08.648018Z","shell.execute_reply":"2025-01-14T10:01:30.053109Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"TRAIN_IMAGE_DIR = \"/kaggle/input/diabetic-retinopathy-dataset/Daataset_DR/DB0/Images\"\nTRAIN_MASK_DIR = \"/kaggle/input/diabetic-retinopathy-dataset/Daataset_DR/DB0/GroundTruth\"\nTEST_IMAGE_DIR = \"/kaggle/input/diabetic-retinopathy-dataset/Daataset_DR/DB1/Images\"\nTEST_MASK_DIR = \"/kaggle/input/diabetic-retinopathy-dataset/Daataset_DR/DB1/GroundTruth\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T10:02:50.405794Z","iopub.execute_input":"2025-01-14T10:02:50.406145Z","iopub.status.idle":"2025-01-14T10:02:50.411362Z","shell.execute_reply.started":"2025-01-14T10:02:50.406119Z","shell.execute_reply":"2025-01-14T10:02:50.409674Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def create_combined_mask(image_filename):\n    sample_mask_path = os.path.join(TRAIN_MASK_DIR, mask_subfolders[0], image_filename)\n    mask_shape = cv2.imread(sample_mask_path, cv2.IMREAD_GRAYSCALE).shape\n    combined_mask = np.zeros(mask_shape, dtype=np.uint8)\n\n    for subfolder in mask_subfolders:\n        mask_path = os.path.join(TRAIN_MASK_DIR, subfolder, image_filename)\n        if os.path.exists(mask_path):\n            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n            combined_mask = cv2.bitwise_or(combined_mask, mask)\n\n    return combined_mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T10:02:51.627655Z","iopub.execute_input":"2025-01-14T10:02:51.628019Z","iopub.status.idle":"2025-01-14T10:02:51.633801Z","shell.execute_reply.started":"2025-01-14T10:02:51.627992Z","shell.execute_reply":"2025-01-14T10:02:51.632604Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"OUTPUT_MASK_DIR = \"/kaggle/working/CombinedMasksTask1\"\nos.makedirs(OUTPUT_MASK_DIR, exist_ok=True)\nmask_subfolders = ['CWS', 'HE']\nimage_filenames = os.listdir(TRAIN_IMAGE_DIR)\n\nfor image_filename in tqdm(image_filenames):\n    combined_mask = create_combined_mask(image_filename)\n    output_path = os.path.join(OUTPUT_MASK_DIR, image_filename)\n    cv2.imwrite(output_path, combined_mask)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T10:02:53.142187Z","iopub.execute_input":"2025-01-14T10:02:53.142619Z","iopub.status.idle":"2025-01-14T10:02:58.600125Z","shell.execute_reply.started":"2025-01-14T10:02:53.142585Z","shell.execute_reply":"2025-01-14T10:02:58.599008Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 130/130 [00:05<00:00, 23.98it/s]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"OUTPUT_MASK_DIR = \"/kaggle/working/CombinedMasksTask2\"\nos.makedirs(OUTPUT_MASK_DIR, exist_ok=True)\nmask_subfolders = ['H', 'MA']\nimage_filenames = sorted(os.listdir(TRAIN_IMAGE_DIR))\n\nfor image_filename in tqdm(image_filenames):\n    combined_mask = create_combined_mask(image_filename)\n    output_path = os.path.join(OUTPUT_MASK_DIR, image_filename)\n    cv2.imwrite(output_path, combined_mask)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T10:02:58.601272Z","iopub.execute_input":"2025-01-14T10:02:58.601601Z","iopub.status.idle":"2025-01-14T10:03:03.780767Z","shell.execute_reply.started":"2025-01-14T10:02:58.601565Z","shell.execute_reply":"2025-01-14T10:03:03.779750Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 130/130 [00:05<00:00, 25.15it/s]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"OUTPUT_MASK_DIR = \"/kaggle/working/TestCombinedMasksTask1\"\nos.makedirs(OUTPUT_MASK_DIR, exist_ok=True)\nmask_subfolders = ['CWS', 'HE']\nimage_filenames = os.listdir(TEST_IMAGE_DIR)\n\nfor image_filename in tqdm(image_filenames):\n    combined_mask = create_combined_mask(image_filename)\n    output_path = os.path.join(OUTPUT_MASK_DIR, image_filename)\n    cv2.imwrite(output_path, combined_mask)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T10:03:03.782512Z","iopub.execute_input":"2025-01-14T10:03:03.782784Z","iopub.status.idle":"2025-01-14T10:03:05.902233Z","shell.execute_reply.started":"2025-01-14T10:03:03.782762Z","shell.execute_reply":"2025-01-14T10:03:05.901116Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 89/89 [00:02<00:00, 42.55it/s]\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"OUTPUT_MASK_DIR = \"/kaggle/working/TestCombinedMasksTask2\"\nos.makedirs(OUTPUT_MASK_DIR, exist_ok=True)\nmask_subfolders = ['H', 'MA']\nimage_filenames = os.listdir(TEST_IMAGE_DIR)\n\nfor image_filename in tqdm(image_filenames):\n    combined_mask = create_combined_mask(image_filename)\n    output_path = os.path.join(OUTPUT_MASK_DIR, image_filename)\n    cv2.imwrite(output_path, combined_mask)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T10:03:05.903596Z","iopub.execute_input":"2025-01-14T10:03:05.903988Z","iopub.status.idle":"2025-01-14T10:03:08.007790Z","shell.execute_reply.started":"2025-01-14T10:03:05.903954Z","shell.execute_reply":"2025-01-14T10:03:08.006815Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 89/89 [00:02<00:00, 42.49it/s]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"IMAGE_DIR = \"/kaggle/input/diabetic-retinopathy-dataset/Daataset_DR/DB0/Images\"\nMASK_DIR = \"/kaggle/working/CombinedMasksTask1\"\n\nIMG_HEIGHT = 1152\nIMG_WIDTH = 1500\nBATCH_SIZE = 1\nEPOCHS = 50\n\ndef load_data(image_dir, mask_dir):\n    image_filenames = sorted(os.listdir(image_dir))\n    images = []\n    masks = []\n    \n    for filename in tqdm(image_filenames, desc=\"Loading data\"):\n        # Load and resize image\n        image_path = os.path.join(image_dir, filename)\n        image = cv2.imread(image_path)\n        #image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n        images.append(image)  # Normalize image to [0, 1]\n        \n        # Load and resize mask\n        mask_path = os.path.join(mask_dir, filename)\n        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n        #mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT))\n        mask = (mask > 0).astype(np.uint8)  # Binarize mask (0 or 1)\n        masks.append(mask)\n    \n    return np.array(images), np.array(masks).reshape(-1, IMG_HEIGHT, IMG_WIDTH, 1)\n\nimages, masks = load_data(IMAGE_DIR, MASK_DIR)\n\nX_train, X_val, y_train, y_val = train_test_split(images, masks, test_size=0.1, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T10:04:23.189509Z","iopub.execute_input":"2025-01-14T10:04:23.189969Z","iopub.status.idle":"2025-01-14T10:04:31.329412Z","shell.execute_reply.started":"2025-01-14T10:04:23.189930Z","shell.execute_reply":"2025-01-14T10:04:31.328300Z"}},"outputs":[{"name":"stderr","text":"Loading data: 100%|██████████| 130/130 [00:07<00:00, 17.60it/s]\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ***UNET***","metadata":{}},{"cell_type":"code","source":"def build_unet(input_shape=(1152, 1500, 3)):\n    inputs = Input(shape=input_shape)\n\n    x = ZeroPadding2D(padding=((0,0),(2,2)))(inputs)  # shape => (1152, 1504, 3)\n\n    # -------- Encoder --------\n    c1 = Conv2D(64, 3, activation='relu', padding='same')(x)\n    c1 = Conv2D(64, 3, activation='relu', padding='same')(c1)\n    p1 = MaxPooling2D(pool_size=(2, 2))(c1)  # shape => (576, 752)\n\n    c2 = Conv2D(128, 3, activation='relu', padding='same')(p1)\n    c2 = Conv2D(128, 3, activation='relu', padding='same')(c2)\n    p2 = MaxPooling2D(pool_size=(2, 2))(c2)  # (288, 376)\n\n    c3 = Conv2D(256, 3, activation='relu', padding='same')(p2)\n    c3 = Conv2D(256, 3, activation='relu', padding='same')(c3)\n    p3 = MaxPooling2D(pool_size=(2, 2))(c3)  # (144, 188)\n\n    c4 = Conv2D(512, 3, activation='relu', padding='same')(p3)\n    c4 = Conv2D(512, 3, activation='relu', padding='same')(c4)\n    p4 = MaxPooling2D(pool_size=(2, 2))(c4)  # (72, 94)\n\n    # -------- Bottleneck --------\n    c5 = Conv2D(1024, 3, activation='relu', padding='same')(p4)\n    c5 = Conv2D(1024, 3, activation='relu', padding='same')(c5)\n\n    # -------- Decoder --------\n    u6 = UpSampling2D((2, 2))(c5)           # (144, 188)\n    u6 = concatenate([u6, c4])             # both (144,188) => OK\n    c6 = Conv2D(512, 3, activation='relu', padding='same')(u6)\n    c6 = Conv2D(512, 3, activation='relu', padding='same')(c6)\n\n    u7 = UpSampling2D((2, 2))(c6)          # (288, 376)\n    u7 = concatenate([u7, c3])             # both (288,376)\n    c7 = Conv2D(256, 3, activation='relu', padding='same')(u7)\n    c7 = Conv2D(256, 3, activation='relu', padding='same')(c7)\n\n    u8 = UpSampling2D((2, 2))(c7)          # (576, 752)\n    u8 = concatenate([u8, c2])             # both (576,752)\n    c8 = Conv2D(128, 3, activation='relu', padding='same')(u8)\n    c8 = Conv2D(128, 3, activation='relu', padding='same')(c8)\n\n    u9 = UpSampling2D((2, 2))(c8)          # (1152,1504)\n    u9 = concatenate([u9, c1])             # both (1152,1504)\n    c9 = Conv2D(64, 3, activation='relu', padding='same')(u9)\n    c9 = Conv2D(64, 3, activation='relu', padding='same')(c9)\n\n    c9_cropped = Cropping2D(cropping=((0,0),(2,2)))(c9)\n    \n    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9_cropped)\n\n    model = Model(inputs=inputs, outputs=outputs)\n    model.compile(\n        optimizer=Adam(learning_rate=1e-4),\n        loss='binary_crossentropy',\n        metrics=[MeanIoU(num_classes=2)]\n    )\n\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T10:04:35.747111Z","iopub.execute_input":"2025-01-14T10:04:35.747534Z","iopub.status.idle":"2025-01-14T10:04:35.760121Z","shell.execute_reply.started":"2025-01-14T10:04:35.747500Z","shell.execute_reply":"2025-01-14T10:04:35.758890Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"unet_model = build_unet((IMG_HEIGHT, IMG_WIDTH, 3))\n\ncheckpoint = ModelCheckpoint(\"unet_model.keras\", save_best_only=True, monitor='val_loss', mode='min')\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n\nhistory = unet_model.fit(\n    X_train, y_train,\n    validation_data=(X_val, y_val),\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    callbacks=[checkpoint, early_stopping]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T10:04:38.443593Z","iopub.execute_input":"2025-01-14T10:04:38.443929Z","execution_failed":"2025-01-14T10:05:33.925Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"TEST_IMAGES = \"/kaggle/input/diabetic-retinopathy-dataset/Daataset DR/DB1/Images\"\nTEST_MASKS = \"/kaggle/working/TestCombinedMasksTask1\"\nX_test, y_test = load_data(TEST_IMAGES, TEST_MASKS)\npredictions = unet_model.predict(X_test, batch_size=1)\nprint(\"Predictions shape:\", predictions.shape)  \n\npred_masks = (predictions > 0.5).astype(np.uint8)\nmean_iou = MeanIoU(num_classes=2)\nmean_iou.update_state(y_test, pred_masks)\nprint(\"Mean IoU on test set:\", mean_iou.result().numpy())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"TEST_IMAGE_PATH = \"/kaggle/input/diabetic-retinopathy-dataset/Daataset DR/DB1/Images/image089.png\"\nMODEL_PATH = \"/kaggle/working/unet_model.keras\"\nGROUND_TRUTH_PATH = \"/kaggle/working/TestCombinedMasksTask1/image089.png\"\n\n# Image dimensions\nIMG_HEIGHT = 1152\nIMG_WIDTH = 1500\n\n# Load the trained model\nmodel = load_model(MODEL_PATH)\n\n# Load and preprocess the test image\ndef load_and_preprocess_image(image_path):\n    image = cv2.imread(image_path)\n    original_size = image.shape[:2]  # Save original size for resizing prediction\n    image_resized = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n    return image, image_resized.reshape(1, IMG_HEIGHT, IMG_WIDTH, 3), original_size\n\noriginal_image, preprocessed_image, original_size = load_and_preprocess_image(TEST_IMAGE_PATH)\n\n# Predict the mask\npredicted_mask = model.predict(preprocessed_image)[0]\npredicted_mask = (predicted_mask > 0.5).astype(np.uint8)  # Threshold to get binary mask\n\n# Resize prediction to original size\npredicted_mask_resized = cv2.resize(predicted_mask, (original_size[1], original_size[0]))\n\n# Load ground truth image\nground_truth_image = cv2.imread(GROUND_TRUTH_PATH, cv2.IMREAD_GRAYSCALE)\nground_truth_image_resized = cv2.resize(ground_truth_image, (original_size[1], original_size[0]))\n\n# Plot the results\nplt.figure(figsize=(18, 6))\nplt.subplot(1, 3, 1)\nplt.title(\"Original Image\")\nplt.imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))\nplt.axis('off')\n\nplt.subplot(1, 3, 2)\nplt.title(\"Predicted Mask\")\nplt.imshow(predicted_mask_resized, cmap='gray')\nplt.axis('off')\n\nplt.subplot(1, 3, 3)\nplt.title(\"Ground Truth Mask\")\nplt.imshow(ground_truth_image_resized, cmap='gray')\nplt.axis('off')\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}